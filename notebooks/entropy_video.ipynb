{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e38f52",
   "metadata": {},
   "source": [
    "# Entropy of each frame in a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ed83e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb699a12",
   "metadata": {},
   "source": [
    "### Hotspot Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292fe45f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def crop_image(img: np.ndarray, hot_spot: dict[str, int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Crops an image based on given coordinates from a hotspot dictionary.\n",
    "    \"\"\"\n",
    "    if img is None or img.shape[0] == 0 or img.shape[1] == 0:\n",
    "        raise ValueError(\"Invalid image: Image is empty or has incorrect dimensions.\")\n",
    "\n",
    "    required_keys = {\"top\", \"left\", \"bottom\", \"right\"}\n",
    "    missing_keys = required_keys - set(hot_spot.keys())\n",
    "    if missing_keys:\n",
    "        raise ValueError(\n",
    "            f\"Invalid hotspot dictionary: Missing required keys: {sorted(missing_keys)}\"\n",
    "        )\n",
    "\n",
    "    if hot_spot[\"left\"] >= hot_spot[\"right\"] or hot_spot[\"top\"] >= hot_spot[\"bottom\"]:\n",
    "        raise ValueError(\"Starting coordinates must be less than ending coordinates.\")\n",
    "\n",
    "    x1 = max(0, hot_spot[\"left\"])\n",
    "    y1 = max(0, hot_spot[\"top\"])\n",
    "    x2 = min(img.shape[1], hot_spot[\"right\"])\n",
    "    y2 = min(img.shape[0], hot_spot[\"bottom\"])\n",
    "\n",
    "    return img[y1:y2, x1:x2]\n",
    "\n",
    "\n",
    "def get_entropy(frame: np.ndarray, hot_spot: dict) -> tuple[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculates the entropy of a cropped region from an image.\n",
    "    Returns (entropy, cropped_region_rgb).\n",
    "    \"\"\"\n",
    "    hot_spot_img = crop_image(frame, hot_spot)\n",
    "    # BGR -> RGB for PIL\n",
    "    hot_spot_img = Image.fromarray(cv2.cvtColor(hot_spot_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    return hot_spot_img.entropy(), cv2.cvtColor(\n",
    "        np.array(hot_spot_img), cv2.COLOR_BGR2RGB\n",
    "    )\n",
    "\n",
    "\n",
    "def process_images_in_folder(image_folder, hotspot, entropy_value):\n",
    "    image_folder = Path(image_folder)\n",
    "    entropy_dict = {}\n",
    "\n",
    "    for image_file in image_folder.glob(\"*.jpg\"):\n",
    "        image = cv2.imread(str(image_file))\n",
    "        if image is None:\n",
    "            print(f\"Failed to load image: {image_file}\")\n",
    "            continue\n",
    "\n",
    "        entropy, hot_spot_img = get_entropy(image, hotspot)\n",
    "        entropy_dict[image_file] = entropy\n",
    "        print(f\"Processing {image_file}, Entropy: {entropy}\")\n",
    "\n",
    "        if entropy < entropy_value:\n",
    "            os.remove(str(image_file))\n",
    "\n",
    "    entropy_list = list(entropy_dict.values())\n",
    "    return entropy_list, entropy_dict\n",
    "\n",
    "\n",
    "def process_video_with_entropy_overlay(\n",
    "    input_video_path: str,\n",
    "    output_video_path: str,\n",
    "    hotspot: dict[str, int],\n",
    "    font_scale: float = 1.0,\n",
    "    thickness: int = 2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads a video, computes entropy for each frame using the hotspot, overlays\n",
    "    the entropy value as text on the frame, and writes a new video.\n",
    "\n",
    "    Args:\n",
    "        input_video_path: Path to the input video.\n",
    "        output_video_path: Path to the output video to be created.\n",
    "        hotspot: Dict with keys 'top', 'bottom', 'left', 'right' for cropping.\n",
    "        font_scale: OpenCV font scale for the text.\n",
    "        thickness: Thickness of the text stroke.\n",
    "\n",
    "    Returns:\n",
    "        List of entropy values, one per frame.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open video: {input_video_path}\")\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the codec and create VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # or 'XVID', depending on your needs\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    entropy_values: list[float] = []\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # End of video\n",
    "\n",
    "        try:\n",
    "            entropy, _ = get_entropy(frame, hotspot)\n",
    "        except ValueError as e:\n",
    "            print(f\"Frame {frame_idx}: error during entropy calculation: {e}\")\n",
    "            # Still write original frame (no entropy text) if desired\n",
    "            out.write(frame)\n",
    "            frame_idx += 1\n",
    "            continue\n",
    "\n",
    "        entropy_values.append(entropy)\n",
    "\n",
    "        # Prepare text to overlay\n",
    "        text = f\"Entropy: {entropy:.4f}\"\n",
    "\n",
    "        # Choose position and font\n",
    "        org = (20, 40)  # (x, y)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "        # Optional: put a filled rectangle behind text to improve readability\n",
    "        (text_w, text_h), baseline = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "        cv2.rectangle(\n",
    "            frame,\n",
    "            (org[0] - 5, org[1] - text_h - 5),\n",
    "            (org[0] + text_w + 5, org[1] + baseline + 5),\n",
    "            (0, 0, 0),  # black background\n",
    "            thickness=cv2.FILLED,\n",
    "        )\n",
    "\n",
    "        # Put text on frame (white text)\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            text,\n",
    "            org,\n",
    "            font,\n",
    "            font_scale,\n",
    "            (255, 255, 255),\n",
    "            thickness,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        # Write the frame with text to output video\n",
    "        out.write(frame)\n",
    "\n",
    "        print(f\"Frame {frame_idx}: {text}\")\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    print(f\"Saved video with entropy overlay to: {output_video_path}\")\n",
    "    return entropy_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5485e49d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "hotspot = {\n",
    "    \"top\": 100,\n",
    "    \"bottom\": 300,\n",
    "    \"left\": 200,\n",
    "    \"right\": 400,\n",
    "}\n",
    "\n",
    "input_video = \"../videos/100_crop1.avi\"\n",
    "output_video = \"../videos/100_crop1_entropy.avi\"\n",
    "\n",
    "entropies = process_video_with_entropy_overlay(\n",
    "    input_video_path=input_video,\n",
    "    output_video_path=output_video,\n",
    "    hotspot=hotspot,\n",
    "    font_scale=0.8,\n",
    "    thickness=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9026a",
   "metadata": {},
   "source": [
    "###  ENTIRE FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df1e72",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def entropy_from_channel(channel):\n",
    "    \"\"\"\n",
    "    Compute Shannon entropy from a single image channel.\n",
    "    \"\"\"\n",
    "    # Flatten to 1D\n",
    "    pixels = channel.flatten()\n",
    "\n",
    "    # Compute histogram with 256 bins\n",
    "    hist, _ = np.histogram(pixels, bins=256, range=(0, 256))\n",
    "\n",
    "    # Convert to probability distribution\n",
    "    p = hist / np.sum(hist)\n",
    "\n",
    "    # Remove zeros\n",
    "    p = p[p > 0]\n",
    "\n",
    "    # Shannon entropy\n",
    "    return -np.sum(p * np.log2(p))\n",
    "\n",
    "def get_entropy_full_frame(frame: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates entropy of the entire frame.\n",
    "\n",
    "    Args:\n",
    "        frame: The input image in BGR color space (as read by OpenCV).\n",
    "\n",
    "    Returns:\n",
    "        Entropy (float)\n",
    "    \"\"\"\n",
    "    # Convert BGR -> RGB for PIL\n",
    "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # R, G, B = cv2.split(img_rgb)\n",
    "    # entropy_R = entropy_from_channel(R)\n",
    "    # return entropy_R\n",
    "    \n",
    "    pil_img = Image.fromarray(img_rgb)\n",
    "    return pil_img.entropy()\n",
    "\n",
    "def process_video_with_entropy_overlay_fullframe(\n",
    "    input_video_path: str,\n",
    "    output_video_path: str,\n",
    "    font_scale: float = 1.0,\n",
    "    thickness: int = 2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates entropy on the FULL FRAME (no hotspot),\n",
    "    overlays the entropy value as text, and writes a new video.\n",
    "    \"\"\"\n",
    "\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open video: {input_video_path}\")\n",
    "\n",
    "    # Get video info\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    entropy_values = []\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # --- ENTROPY OF ENTIRE FRAME ---\n",
    "        entropy = get_entropy_full_frame(frame)\n",
    "        entropy_values.append(entropy)\n",
    "\n",
    "        text = f\"Entropy: {entropy:.4f}\"\n",
    "        org = (20, 40)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "        # Draw readable box behind text\n",
    "        (tw, th), baseline = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "        cv2.rectangle(\n",
    "            frame,\n",
    "            (org[0] - 5, org[1] - th - 5),\n",
    "            (org[0] + tw + 5, org[1] + baseline + 5),\n",
    "            (0, 0, 0),\n",
    "            thickness=cv2.FILLED,\n",
    "        )\n",
    "\n",
    "        # Draw text\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            text,\n",
    "            org,\n",
    "            font,\n",
    "            font_scale,\n",
    "            (255, 255, 255),\n",
    "            thickness,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        out.write(frame)\n",
    "        print(f\"Frame {frame_idx}: Entropy = {entropy:.4f}\")\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Saved entropy video to {output_video_path}\")\n",
    "\n",
    "    return entropy_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b0c8c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "input_video = \"../videos/100_crop1.avi\"\n",
    "output_video = \"../videos/100_crop1_entropy.avi\"\n",
    "\n",
    "entropies = process_video_with_entropy_overlay_fullframe(\n",
    "    input_video_path=input_video,\n",
    "    output_video_path=output_video,\n",
    "    font_scale=0.8,\n",
    "    thickness=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b6333",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1464ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d0c2a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandhyaparna/CV-Training/blob/main/notebooks/OCR/01_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "876c3b95",
      "metadata": {
        "id": "876c3b95"
      },
      "source": [
        "# Apple Vision Framework"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install packages"
      ],
      "metadata": {
        "id": "s14GHthcp5hO"
      },
      "id": "s14GHthcp5hO"
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install opencv-python pillow pyobjc-framework-Vision pyobjc jaro_winkler"
      ],
      "metadata": {
        "id": "L9X-CEr1p7ed"
      },
      "id": "L9X-CEr1p7ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Packages"
      ],
      "metadata": {
        "id": "ly_HDtgIp9BG"
      },
      "id": "ly_HDtgIp9BG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edbe2754",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "edbe2754"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import string\n",
        "import time\n",
        "import jaro\n",
        "import cv2\n",
        "import Quartz\n",
        "import Vision\n",
        "from Cocoa import NSURL\n",
        "from IPython.display import Image, display\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from typing import List\n",
        "from apple_vision_utils import get_ocr_observations, extract_recognized_text, remove_after_special_char, split_text, draw_text_on_image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83977889",
      "metadata": {
        "id": "83977889"
      },
      "source": [
        "### Perform OCR on a single image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1766999",
      "metadata": {
        "id": "b1766999"
      },
      "source": [
        "##### Run Vision framework on one of the images\n",
        "* RAW OUTPUT contains confidence score and the bounding box coordinates for the predicted text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"../x.jpeg\"\n",
        "observations = get_ocr_observations(img_path)\n",
        "print(\"RAW OBSERVATIONS: \\n\", observations)"
      ],
      "metadata": {
        "id": "BYPFg9TGqG0w"
      },
      "id": "BYPFg9TGqG0w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Recognized text in the image:\", extract_recognized_text(observations))"
      ],
      "metadata": {
        "id": "zAIfw6HKqGyq"
      },
      "id": "zAIfw6HKqGyq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Strings after the predicted text is split into subphrases:"
      ],
      "metadata": {
        "id": "KMLOM_Xd4nez"
      },
      "id": "KMLOM_Xd4nez"
    },
    {
      "cell_type": "code",
      "source": [
        "split_strings_list = [word for text in extract_recognized_text(observations) for word in split_text(text)]\n",
        "print(split_strings_list)"
      ],
      "metadata": {
        "id": "d9gPdfGt4hgW"
      },
      "id": "d9gPdfGt4hgW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display an image with bounding box and text for OCR"
      ],
      "metadata": {
        "id": "KTjAXLGj4rSp"
      },
      "id": "KTjAXLGj4rSp"
    },
    {
      "cell_type": "code",
      "source": [
        "# observations = get_ocr_observations(img_path)\n",
        "recognized_text = []\n",
        "bounding_boxes = []\n",
        "\n",
        "for observation in observations:\n",
        "    # Get the top candidate text string\n",
        "    recognized_text.append(observation.topCandidates_(1)[0].string())\n",
        "    # Get the bounding box for the recognized text\n",
        "    bounding_boxes.append(observation.boundingBox())\n",
        "\n",
        "recognized_text, bounding_boxes\n",
        "\n",
        "draw_text_on_image(img_path, zip(recognized_text, bounding_boxes))"
      ],
      "metadata": {
        "id": "sTA6IfnS4hdm"
      },
      "id": "sTA6IfnS4hdm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_name = \"TJ.jpeg\"\n",
        "img_path = f\"../data/{img_name}\"\n",
        "\n",
        "observations = get_ocr_observations(img_path)\n",
        "print(\"RAW OBSERVATIONS: \\n\", observations)"
      ],
      "metadata": {
        "id": "Z3xx-nmH4haf"
      },
      "id": "Z3xx-nmH4haf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apple_vision_framework_ocr_text(img_path)"
      ],
      "metadata": {
        "id": "vMIGwy4r64It"
      },
      "id": "vMIGwy4r64It",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Recognized text in the image:\", extract_recognized_text(observations))"
      ],
      "metadata": {
        "id": "DL3Om2ys4hT4"
      },
      "id": "DL3Om2ys4hT4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_strings_list = [word for text in extract_recognized_text(observations) for word in split_text(text)]\n",
        "print(split_strings_list)"
      ],
      "metadata": {
        "id": "KLlvjIdH4hMq"
      },
      "id": "KLlvjIdH4hMq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess results\n",
        "processed_results = {remove_after_special_char(word.lower()) for word in split_strings_list}\n",
        "processed_results"
      ],
      "metadata": {
        "id": "iq9cJ04TqGwB"
      },
      "id": "iq9cJ04TqGwB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check if one of the n labels is present in the text\n",
        "Final logic to detect label of an image:\n",
        "* OCR is performed on the whole image\n",
        "* If the click dimensions are inside the bounding box coordinates of any result from the OCR, only that particular text is pre-processed and is evaluated using the below criteria to determine the label:\n",
        "    * If the pre-prcoessed substring is part of any of the labels\n",
        "    * else - evaluate the jaro winkler similarity of the pre-prcoessed text against all the labels, and output the label which have the highest Jaro Winkler similarity metric"
      ],
      "metadata": {
        "id": "kxx0TskR46SO"
      },
      "id": "kxx0TskR46SO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This code uses two label sets"
      ],
      "metadata": {
        "id": "hNETMUGM6crI"
      },
      "id": "hNETMUGM6crI"
    },
    {
      "cell_type": "code",
      "source": [
        "labels_set1 = {\"x\", \"y\", \"z\"}\n",
        "labels_list2 = [{'a', 'b'},\n",
        "{'c', 'd'},\n",
        "{'e', 'f'}]\n",
        "\n",
        "# Step 1: Attempt a direct match between two sets of labels\n",
        "# 'labels_set1' is a predefined set of labels\n",
        "# 'processed_results' is a set of processed text\n",
        "direct_match = labels_set1.intersection(processed_results)\n",
        "\n",
        "# If there is any overlap (i.e., direct match found), print the matching labels\n",
        "if direct_match:\n",
        "    print(direct_match)\n",
        "else:\n",
        "    # Step 2: If no direct match, attempt a secondary match using a list of label combinations\n",
        "    # 'labels_list2' is a list of lists or tuples, where each sublist contains multiple words\n",
        "    # The goal is to find a sublist where at least two words are present in 'processed_results'\n",
        "    secondary_match = next(\n",
        "        (label_combo for label_combo in labels_list2 if sum(1 for word in label_combo if word in processed_results) >= 2),\n",
        "        None  # If no such combination is found, return None\n",
        "    )\n",
        "\n",
        "    # If a secondary match is found, print it\n",
        "    if secondary_match:\n",
        "        print(secondary_match)\n",
        "    else:\n",
        "        # Step 3: As a final fallback, use fuzzy matching with the Jaro-Winkler similarity metric\n",
        "        # This helps catch near matches that aren't exact due to typos, formatting, etc.\n",
        "        found_match = False  # Flag to indicate if a fuzzy match is found\n",
        "\n",
        "        # Iterate through each result in the processed results\n",
        "        for result in processed_results:\n",
        "            # Compare it against each label in the primary label set\n",
        "            for label in labels_set1:\n",
        "                # Compute the Jaro-Winkler similarity score between the result and the label\n",
        "                jaro_winkler_metric = jaro.jaro_winkler_metric(result, label)\n",
        "\n",
        "                # If the similarity score is above a threshold (e.g., 0.8), consider it a match\n",
        "                if jaro_winkler_metric > 0.8:\n",
        "                    print(label)  # Print the matched label\n",
        "                    found_match = True\n",
        "                    break  # Exit the inner loop once a match is found\n",
        "\n",
        "            if found_match:\n",
        "                break  # Exit the outer loop as well once a match is found\n"
      ],
      "metadata": {
        "id": "_DjfB0CnqGtT"
      },
      "id": "_DjfB0CnqGtT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This code uses label dict instead of two label sets"
      ],
      "metadata": {
        "id": "WH92PJir6iA_"
      },
      "id": "WH92PJir6iA_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a38695e",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "5a38695e"
      },
      "outputs": [],
      "source": [
        "labels_dict = {\n",
        "    \"x\": \"A\",\n",
        "    \"y\": \"B\",\n",
        "    \"z\": \"C\",\n",
        "}\n",
        "\n",
        "# Collect all direct matches (exact string matches) from processed_results\n",
        "# using the keys in labels_dict. The values are the standardized labels.\n",
        "direct_match = {labels_dict[result] for result in processed_results if result in labels_dict.keys()}\n",
        "\n",
        "# If at least one direct match is found\n",
        "if direct_match:\n",
        "    # Exactly one label found → success\n",
        "    if len(direct_match) == 1:\n",
        "        print(\"direct_match\",direct_match)\n",
        "    # More than one different label was matched → ambiguous result\n",
        "    else:\n",
        "        print(\"more than 2 labels found, retake image\")\n",
        "\n",
        "# If no direct match, try fuzzy matching\n",
        "else:\n",
        "    similarity_match = set()\n",
        "    # Iterate through each result in the processed results\n",
        "    for result in processed_results:\n",
        "        # Compare it against each label in the primary label set\n",
        "        for text, label  in labels_dict.items():\n",
        "            # Compute the Jaro-Winkler similarity score between the result and the label\n",
        "            jaro_winkler_score = jaro.jaro_winkler_metric(result, text)\n",
        "            # If the similarity score is above a threshold (e.g., 0.8), consider it a match\n",
        "            if jaro_winkler_score > 0.8:\n",
        "                similarity_match.add(label)\n",
        "\n",
        "    # If we found at least one fuzzy match\n",
        "    if similarity_match:\n",
        "        # Exactly one fuzzy match found → success\n",
        "        if len(similarity_match) == 1:\n",
        "            print(\"fuzzy_match\",similarity_match)\n",
        "        # Multiple fuzzy matches found → ambiguous\n",
        "        else:\n",
        "            print(\"more than 2 labels found, retake image\")\n",
        "\n",
        "    # Neither direct nor fuzzy match found\n",
        "    else:\n",
        "        print(\"no confident match found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e061a3",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "70e061a3"
      },
      "outputs": [],
      "source": [
        "if direct_match and len(direct_match) == 1:\n",
        "        print(\"direct_match\",direct_match)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f24df32c",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "f24df32c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "876c3b95",
   "metadata": {},
   "source": [
    "# CLASSIFICATION TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe2754",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os; os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import sys\n",
    "sys.path.append(\"../../../../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54c01c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# general imports\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, ConcatDataset\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import json\n",
    "from torchvision.models import mobilenet_v3_small, efficientnet_b0, resnet18, densenet121\n",
    "from torchvision.models import MobileNet_V3_Small_Weights, EfficientNet_B0_Weights, ResNet18_Weights, DenseNet121_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1929e87e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from classification.annotator import manifest2classification, multilabel2dataframe\n",
    "from classification.dataset import ClassificationDataset\n",
    "from classification.utils import get_mean_and_std, plot_label_distribution\n",
    "from classification.trainer import ClassificationTrainer, calculate_metrics, FocalLoss\n",
    "from classification.visualizer import visualize, save_model_errors, plot_loss_function, generate_confusion_matrix_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83977889",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1766999",
   "metadata": {},
   "source": [
    "### Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a38695e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# type of task\n",
    "task_type = \"multiclass\" # or \"multilabel\". If you are not sure, try \"multiclass\"\n",
    "\n",
    "# define the classes\n",
    "classes = [\"label1\", \"label2\", \"label3\"]\n",
    "\n",
    "# Label file location\n",
    "# manifest file for multiclass OR json file for multilabel classification\n",
    "label_file = \"../../data/raw/v2_output.manifest\"\n",
    "\n",
    "# path to raw images\n",
    "images_path = Path(\"../../data/raw/s3_v2_images\")\n",
    "\n",
    "# get the label key from the manifest file\n",
    "label_key = \"label-metadata\"\n",
    "\n",
    "# device name (use \"cuda\" if you are using Sagemaker)\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# input image size\n",
    "input_image_size = 224\n",
    "\n",
    "# batch size\n",
    "batch_size = 32\n",
    "\n",
    "# epochs\n",
    "n_epochs = 5\n",
    "\n",
    "# loss fn\n",
    "loss_alpha = 3\n",
    "loss_gamma = 2\n",
    "model_loss_fn = FocalLoss(alpha=loss_alpha, gamma=loss_gamma)\n",
    "\n",
    "# Name of the model file to be saved\n",
    "model_file_name = \"classifier_project\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de972691",
   "metadata": {},
   "source": [
    "### Split raw data into train & validation across labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377e83c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if task_type == \"multiclass\":\n",
    "    manifest2classification(label_file, images_path, label_key)\n",
    "    annotations_df_train = annotations_df_validation = None\n",
    "elif task_type == \"multilabel\":\n",
    "    annotations_df_train, annotations_df_validation = multilabel2dataframe(label_file, classes)\n",
    "else:\n",
    "    print(\"The type of task must be either multilabel or multiclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd9c28a",
   "metadata": {},
   "source": [
    "### Plot distribution of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad3af8b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plot_label_distribution(images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0101dd",
   "metadata": {},
   "source": [
    "### Extract mean and std of Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b42a533",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((input_image_size, input_image_size)),\n",
    "    transforms.ToTensor()]\n",
    ")\n",
    "train_dataset = datasets.ImageFolder(root = images_path/\"train\", transform = train_transforms)\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size=32, shuffle=False)\n",
    "mean, std = get_mean_and_std(train_loader)\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89af82f",
   "metadata": {},
   "source": [
    "### Apply transformations of Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52374e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'base': transforms.Compose([\n",
    "        transforms.Resize((input_image_size, input_image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'aug': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=input_image_size, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(p=0.1),\n",
    "        transforms.RandomRotation(degrees=(-10, 10)),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffc61b9",
   "metadata": {},
   "source": [
    "### Generate Training and Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d94b1d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "base_dataset = ClassificationDataset(\n",
    "    images_path / \"train\", classes, task_name = task_type, transform = data_transforms['base'], annotations_df = annotations_df_train)\n",
    "\n",
    "augmented_dataset = ClassificationDataset(\n",
    "    images_path / \"train\", classes, task_name = task_type, transform = data_transforms['aug'], annotations_df = annotations_df_train)\n",
    "\n",
    "# Concatenate the original and augmented datasets to form train dataset\n",
    "train_dataset = ConcatDataset([base_dataset, augmented_dataset])\n",
    "\n",
    "\n",
    "validation_dataset = ClassificationDataset(\n",
    "    images_path / \"validation\", classes, task_name = task_type, transform = data_transforms['base'], annotations_df = annotations_df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607145d8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5c958c",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f3f0ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Choose (model, pre-trained weight) combo from the below list\n",
    "# [\"mobilenet_v3_small\", \"MobileNet_V3_Small_Weights\"]\n",
    "# [\"mobilenet_v3_large\", \"MobileNet_V3_Large_Weights\"]\n",
    "# [\"alexnet\", \"AlexNet_Weights\"]\n",
    "# [\"densenet121\", \"DenseNet121_Weights\"]\n",
    "# [\"efficientnet_b0\", \"EfficientNet_B0_Weights\"]\n",
    "# [\"efficientnet_v2_s\", \"EfficientNet_V2_S_Weights\"]\n",
    "# [\"efficientnet_v2_m\", \"EfficientNet_V2_M_Weights\"]\n",
    "# [\"efficientnet_v2_l\", \"EfficientNet_V2_L_Weights\"]\n",
    "# [\"inception_v3\", \"Inception_V3_Weights\"]\n",
    "# [\"resnet18\", \"ResNet18_Weights\"]\n",
    "# [\"resnet50\", \"ResNet50_Weights\"]\n",
    "# [\"vgg16\", \"VGG16_Weights\"]\n",
    "# [\"vit_b_16\", \"ViT_B_16_Weights\"]\n",
    "# For more models chek out https://pytorch.org/vision/stable/models.html#classification\n",
    "\n",
    "# [\"mobilenet_v3_small\", \"MobileNet_V3_Small_Weights\"] is selected by default\n",
    "model_details = [\"mobilenet_v3_small\", \"MobileNet_V3_Small_Weights\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365fd928",
   "metadata": {},
   "source": [
    "### Define a Trainer for your model with customizable hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b543f9f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "trainer = ClassificationTrainer(classes,\n",
    "                                train_loader,\n",
    "                                val_loader,\n",
    "                                batch_size,\n",
    "                                batch_size*2,\n",
    "                                model_details,\n",
    "                                task_type,\n",
    "                                loss_fun = model_loss_fn,\n",
    "                                num_epochs = n_epochs,\n",
    "                                patience = 3,\n",
    "                                criterion = \"val_f2\",\n",
    "                                model_file_name_prefix = model_file_name\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e6e5f1",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6dfd82",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "metrics_dict = trainer.train()\n",
    "print(\"Time for training:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11697c6b",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f011564",
   "metadata": {},
   "source": [
    "### Generate loss function graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f6f9a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "metrics_dict = plot_loss_function(metrics_dict, model_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca88934",
   "metadata": {},
   "source": [
    "### Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f0364",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "classifier_model = mobilenet_v3_small(\n",
    "        weights=MobileNet_V3_Small_Weights.DEFAULT\n",
    "    )\n",
    "classifier_model.classifier[3] = nn.Linear(\n",
    "    in_features=1024, out_features=3, bias=True\n",
    ")\n",
    "classifier_model.load_state_dict(torch.load(f\"{model_file_name}.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c352902",
   "metadata": {},
   "source": [
    "### Generate Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcf8609",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix = generate_confusion_matrix_plot(val_loader, classifier_model, \"cpu\", classes, model_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a83e4",
   "metadata": {},
   "source": [
    "### Save Model Performance and corresponding hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba969c4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# modify tensors\n",
    "metrics_dict['val_loss'] = [val.item() for val in metrics_dict['val_loss']]\n",
    "\n",
    "model_parameters = {\n",
    "    \"name\": model_file_name,\n",
    "    \"model_details\": model_details,\n",
    "\n",
    "    \"batch_size\": batch_size,\n",
    "    \"input_image_size\": input_image_size,\n",
    "    \"augmentation\":str(data_transforms[\"aug\"]),\n",
    "    \"epochs\": n_epochs,\n",
    "    \"loss\": str(model_loss_fn),\n",
    "    \"loss_alpha\": loss_alpha,\n",
    "    \"loss_gamma\": loss_gamma,\n",
    "\n",
    "    \"n_train\": len(train_dataset),\n",
    "    \"n_val\": len(validation_dataset),\n",
    "    \"perf_metrics\":metrics_dict,\n",
    "\n",
    "    \"class_labels\": classes,\n",
    "    \"confusion_matrix\": str(confusion_matrix)\n",
    "}\n",
    "\n",
    "metadata_json_path = f\"{model_file_name}.json\"\n",
    "with open(metadata_json_path, \"w\") as outfile:\n",
    "    outfile.write(json.dumps(model_parameters, indent=4))\n",
    "print(f\"Saved model params to {metadata_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcd8e23",
   "metadata": {},
   "source": [
    "# Visualize Random Correct and Incorrect Examples \n",
    "(One Each) from Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79269a2e",
   "metadata": {},
   "source": [
    "(Only for 'multiclass' task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0771402",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# name of the class you want to visualize\n",
    "viz_class_name = \"label1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99bf8e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# create new dataloader\n",
    "# use batch size 1, and set shuffle to True\n",
    "val_loader = DataLoader(validation_dataset, 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc7eda7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# vizualize examples\n",
    "visualize(viz_class_name, trainer, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa0d9e6",
   "metadata": {},
   "source": [
    "### Analysis of Validation Set Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e10810",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# create new dataloader\n",
    "# use batch size 1, and set shuffle to True\n",
    "val_loader = DataLoader(validation_dataset, 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f9512",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "error_dict = save_model_errors(trainer, val_loader)\n",
    "error_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e061a3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24df32c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
